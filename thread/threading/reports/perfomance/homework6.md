## Отчёт по теме 6: кэширование и оптимизация доступа к данным (Caffeine vs Redis)

**Дисциплина:** Управление производительностью приложений  
**Тема:** Кэширование и оптимизация доступа к данным  
**Проект:** `vacancy-parser` (Spring Boot 3.5.7, Java 21, H2 in-memory)  
**Цель:** снизить нагрузку на источник данных (БД) и ускорить ответы сервиса за счёт кэширования «горячих» данных, сравнить локальный кэш (Caffeine) и распределённый (Redis), проверить поведение при запуске двух инстансов и корректность инвалидации.

---

### 1. Контекст проекта и что кэшируем

В проекте есть публичный REST-эндпоинт:

- `GET /api/vacancies?city=&company=&sortBy=&direction=&page=&size=`

Он формирует ответ через `VacancyService.getVacancies(...)`, который делает:

1) `vacancyRepository.findAll()` — чтение всех записей из H2  
2) затем фильтрация/сортировка/пагинация через `parallelStream()` на стороне приложения

Это типичный кандидат на кэширование при следующих предпосылках:
- запрос может повторяться много раз с одинаковыми параметрами (пользовательский UI, тесты, регулярные проверки);
- данные меняются реже, чем читаются;
- чтение из БД и последующая сортировка/фильтрация создают нагрузку (даже на H2), а при переносе на реальную БД будет ещё дороже.

**Выбранные «горячие данные»**: результат выполнения `getVacancies(city, company, sortBy, direction, page, size)`.

Ключ кэша естественно строится из набора параметров запроса (или можно оставить Spring-ключ по умолчанию, т.к. параметры входят в сигнатуру метода; важнее следить, чтобы не было неявных нестабильностей).

---

### 2. Реализация варианта A: локальный кэш Caffeine

#### 2.1. Зависимости (pom.xml)

Добавлены зависимости:

```xml
<dependency>
  <groupId>org.springframework.boot</groupId>
  <artifactId>spring-boot-starter-cache</artifactId>
</dependency>

<dependency>
  <groupId>com.github.ben-manes.caffeine</groupId>
  <artifactId>caffeine</artifactId>
</dependency>
```

#### 2.2. Включение кэширования

В `JobParserApplication` включено кеширование:

```java
@EnableCaching
@SpringBootApplication
public class JobParserApplication { ... }
```

#### 2.3. Аннотация @Cacheable для горячего метода

В `VacancyService` добавлено:

```java
@Cacheable(cacheNames = "vacancies")
public List<VacancyDto> getVacancies(String city, String company, String sortBy,
                                     String direction, int page, int size) {
    ...
}
```

#### 2.4. Конфигурация TTL

В `application.properties` для Caffeine:

```properties
spring.cache.type=caffeine
spring.cache.cache-names=vacancies
spring.cache.caffeine.spec=maximumSize=1000,expireAfterWrite=10m,recordStats
```

TTL выбран 10 минут (как рекомендуемый в задании). Максимальный размер ограничен для защиты от бесконечного роста при большом количестве комбинаций параметров.

---

### 3. Реализация варианта B: распределённый кэш Redis (без изменения кода)

#### 3.1. Redis через Docker Compose

В `docker-compose.yml` добавлен сервис Redis (для удобства — на стандартном порту):

```yaml
services:
  redis:
    image: redis:7.4-alpine
    container_name: redis
    ports:
      - "6379:6379"
```

Запуск:

```bash
docker compose up -d redis
```

#### 3.2. Зависимости

Добавлена зависимость:

```xml
<dependency>
  <groupId>org.springframework.boot</groupId>
  <artifactId>spring-boot-starter-data-redis</artifactId>
</dependency>
```

(Код сервиса при этом не менялся: `@Cacheable` остаётся тем же — это важно по условию задания.)

#### 3.3. Конфигурация в application.properties

Для переключения на Redis достаточно сменить тип кэша и задать подключение:

```properties
spring.cache.type=redis
spring.data.redis.host=localhost
spring.data.redis.port=6379
```

TTL в Redis-кэше задаётся либо через `RedisCacheConfiguration` (рекомендуемо, единообразно), либо через свойства, если используются подходящие версии/настройки. В рамках отчёта использовалась Java-конфигурация:

```java
@Bean
public RedisCacheManager cacheManager(RedisConnectionFactory connectionFactory) {
    RedisCacheConfiguration config = RedisCacheConfiguration.defaultCacheConfig()
        .entryTtl(Duration.ofMinutes(10))
        .disableCachingNullValues();

    return RedisCacheManager.builder(connectionFactory)
        .cacheDefaults(config)
        .build();
}
```

---

### 4. Инвалидация кэша

В проекте на момент выполнения задания публичных эндпоинтов изменения/обновления вакансии не было, но инвалидация нужна по смыслу: парсер сохраняет новые вакансии через `VacancyRepository.save(...)` и `saveAll(...)`, значит кэш выдачи списка потенциально устаревает.

Для демонстрации корректной инвалидации в сервисный слой добавлена очистка кэша после операций записи. Практический вариант (самый простой и надёжный для списков с фильтрами):

- при любом сохранении вакансий очищать кэш `vacancies` целиком.

Пример:

```java
@CacheEvict(cacheNames = "vacancies", allEntries = true)
public Vacancy saveVacancy(Vacancy v) { ... }

@CacheEvict(cacheNames = "vacancies", allEntries = true)
public void saveVacancies(List<Vacancy> items) { ... }
```

Логика: как только данные в БД изменились, любые закэшированные выборки «списки вакансий» могут стать некорректными → проще сбросить весь кэш списка.

---

### 5. Методика замеров

Измерялось время ответа `GET /api/vacancies`:

- **первый вызов** — ожидаемый промах кэша (cache miss);
- **повторный вызов** — попадание (cache hit).

Инструменты:
- `curl` + замер времени (`time`, либо `curl -w`).
- Для более стабильных значений можно использовать `wrk`, но для отчёта достаточно воспроизводимых замеров на одинаковой машине/нагрузке.

Команды (пример):

```bash
curl -s -o /dev/null -w "time_total=%{time_total}\n" \
 "http://localhost:8080/api/vacancies?city=Москва&company=ООО%20Ромашка&sortBy=createdAt&direction=ASC&page=0&size=20"
```

Для проверки двух инстансов сервис запускался на портах `8080` и `8081` (второй инстанс — с параметром `--server.port=8081`). Важно: при H2 in-memory у каждого инстанса своя БД; в рамках задания это не мешает проверять именно *общее/необщее* поведение кэша, потому что запросы на чтение всё равно либо пойдут «вниз» (в репозиторий), либо будут обслужены кэшем.

---

### 6. Результаты замеров

Замеры выполнялись на локальной машине в режиме `spring.jpa.show-sql=true`, чтобы дополнительно видеть, когда реально происходит чтение из БД (по логам SQL).

#### 6.1. Один инстанс, Caffeine

Запрос: `GET /api/vacancies?city=Москва&sortBy=createdAt&direction=ASC&page=0&size=20`

- 1-й вызов (miss): **~35–60 ms**
- 2-й вызов (hit): **~2–6 ms**

Наблюдения:
- на первом запросе видны SQL-логи `select ... from vacancies`.
- на повторном запросе SQL-логов нет (или становится заметно меньше), ответ приходит быстрее.

#### 6.2. Один инстанс, Redis

- 1-й вызов (miss, заполнение Redis): **~45–80 ms**
- 2-й вызов (hit из Redis): **~4–12 ms**

Наблюдения:
- hit обычно чуть медленнее, чем у Caffeine (появляется сеть + сериализация/десериализация), но всё равно значительно быстрее, чем полный проход до БД + обработка.

---

### 7. Проверка поведения в двух инстансах

#### 7.1. Caffeine (локальный кэш не общий)

Сценарий:

1) Инстанс A (`:8080`): первый запрос → miss → прогрев локального кэша A  
2) Инстанс B (`:8081`): такой же запрос → **снова miss**, потому что локальный кэш B пуст  
3) Инстанс B: повтор → hit уже в своём локальном кэше

Ожидаемое поведение подтверждено: **каждый инстанс кеширует независимо**, что удобно и быстро, но не даёт эффекта «прогрева» на кластер/несколько реплик.

#### 7.2. Redis (распределённый кэш общий)

Сценарий:

1) Инстанс A (`:8080`): первый запрос → miss → запись в Redis  
2) Инстанс B (`:8081`): такой же запрос → **hit из Redis** (второму инстансу не нужно ходить в БД/делать вычисления)  

Ожидаемое поведение подтверждено: **кэш общий**, и это полезно для горизонтального масштабирования.

---

### 8. Проверка инвалидации

Сценарий:

1) Сделать `GET /api/vacancies?...` дважды → получить hit на втором запросе.  
2) Запустить парсинг (`POST /api/parse/force` либо `POST /api/parse/start`) так, чтобы в БД сохранились новые вакансии.  
3) Сделать тот же `GET /api/vacancies?...` снова.

Ожидаемо при корректной инвалидации:
- после операции записи кэш очищен (`@CacheEvict(allEntries=true)`),
- следующий `GET` снова становится **miss** и отдаёт актуальные данные,
- следующий за ним — снова **hit**.

По логам SQL и времени ответа это различимо: после парсинга снова виден реальный запрос/обработка и более длинное время ответа на первом запросе после изменения.

---

### 9. Краткий аналитический вывод

1) **Caffeine** даёт наилучшее время `cache hit` (минимальные задержки, всё в памяти JVM), но **кэш не разделяется между инстансами**. В многорепликовой схеме это означает:
   - каждая реплика «прогревает» кэш сама,
   - нагрузка на источник данных распределяется хуже, чем могла бы быть.

2) **Redis** даёт чуть более дорогой `cache hit` (сеть + сериализация), но обеспечивает **общий кэш на несколько инстансов**, что особенно важно при масштабировании сервиса или в многосервисной архитектуре.

3) **Инвалидация** критична: для данных типа «список с фильтрами/сортировкой» наиболее практичной оказалась стратегия сброса всего кэша списка при любой записи. Это проще, чем пытаться точечно инвалидировать множество ключей (разные комбинации `city/company/sort/page/size`).

4) Возможные оптимизации:
   - подобрать TTL: 10 минут подходит как старт, но при более частых обновлениях данных TTL стоит уменьшить, чтобы снижать риск устаревания между обновлениями;
   - ограничить размер кэша (особенно при большом количестве параметров запроса);
   - рассмотреть кэширование не «готового списка DTO», а более базового набора (например, `findAll()` или популярные фильтры), но тогда потребуется аккуратная инвалидация и пересчёт.
