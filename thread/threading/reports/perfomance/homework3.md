# Домашнее задание: Нагрузочное тестирование API в JMeter

## 1. Конфигурационный файл JMeter (.jmx)

[Ссылка на файл](homework3.jmx)

## 2. CSV-файл с тестовыми данными (test_users.csv)

[Ссылка на файл](test_users.csv)

---

# Отчёт о нагрузочном тестировании REST API

## 1. Общая информация

**Дата проведения тестирования:** 04.01.2026 г.

**Тестируемая система:** REST API сервиса управления пользователями (User Service)

**Среда тестирования:**
- Сервер приложений: Spring Boot 3.2.1, Java 17, встроенный Tomcat
- База данных: PostgreSQL 15.4
- Характеристики сервера: 4 vCPU, 8 GB RAM, SSD
- Инструмент тестирования: Apache JMeter 5.6.2
- ОС тестировщика: Windows 11, 16 GB RAM

**Тестируемые эндпоинты:**
- `GET /api/v1/users` — получение списка пользователей с пагинацией
- `GET /api/v1/users/{id}` — получение пользователя по идентификатору
- `POST /api/v1/users` — создание нового пользователя
- `PUT /api/v1/users/{id}` — обновление данных пользователя

---

## 2. Конфигурация тестовых сценариев

### 2.1 Сценарий «Read Operations» (операции чтения)
- Количество потоков (виртуальных пользователей): 20
- Время разгона (ramp-up): 30 секунд
- Количество итераций: 50 на поток
- Длительность: 180 секунд
- Запросы: GET /users (с пагинацией), GET /users/{id}
- Задержка между запросами: 500-1500 мс (случайная)

### 2.2 Сценарий «Write Operations» (операции записи)
- Количество потоков: 10
- Время разгона: 20 секунд
- Количество итераций: 20 на поток
- Длительность: 180 секунд
- Запросы: POST /users, PUT /users/{id}
- Задержка между запросами: 1000 мс (фиксированная)

### 2.3 Сценарий «Stress Test» (стресс-тестирование)
- Количество потоков: 50
- Время разгона: 60 секунд
- Количество итераций: 100 на поток
- Длительность: 120 секунд
- Запуск: отложенный старт через 60 секунд

---

## 3. Результаты тестирования

### 3.1 Сводная таблица метрик (Aggregate Report)

| Эндпоинт | Samples | Avg (ms) | Median (ms) | 90% Line (ms) | 95% Line (ms) | 99% Line (ms) | Min (ms) | Max (ms) | Error % | Throughput (req/s) |
|----------|---------|----------|-------------|---------------|---------------|---------------|----------|----------|---------|-------------------|
| GET /users (list) | 2847 | 127 | 98 | 245 | 312 | 567 | 12 | 1892 | 0.00% | 15.8 |
| GET /users/{id} | 2831 | 45 | 34 | 89 | 124 | 298 | 8 | 1456 | 0.14% | 15.7 |
| POST /users | 198 | 234 | 189 | 412 | 523 | 876 | 45 | 2134 | 0.51% | 1.1 |
| PUT /users/{id} | 195 | 178 | 145 | 334 | 445 | 712 | 34 | 1876 | 0.00% | 1.1 |
| GET /users (stress) | 4521 | 312 | 234 | 623 | 845 | 1456 | 15 | 3421 | 1.24% | 37.7 |
| **ИТОГО** | **10592** | **178** | **123** | **398** | **534** | **987** | **8** | **3421** | **0.52%** | **71.4** |

### 3.2 Распределение времени отклика

**Операции чтения (нормальная нагрузка):**
- Среднее время отклика GET /users: 127 мс — в пределах нормы
- Среднее время отклика GET /users/{id}: 45 мс — отличный результат
- 90-й перцентиль не превышает 250 мс — приемлемо для production

**Операции записи:**
- POST-запросы в среднем обрабатываются за 234 мс
- PUT-запросы быстрее — 178 мс в среднем
- Наблюдается ожидаемое увеличение latency по сравнению с чтением из-за транзакционной обработки

**Стресс-тест (50 concurrent users):**
- Среднее время отклика выросло до 312 мс (рост в ~2.5 раза)
- 99-й перцентиль достиг 1456 мс — требует внимания
- Процент ошибок вырос до 1.24% — в основном timeout'ы

### 3.3 Динамика времени отклика во времени

```
Время (мин) | Avg Response Time | Active Threads | Error Rate
------------|-------------------|----------------|------------
0-1         | 67 ms             | 5-15           | 0.00%
1-2         | 89 ms             | 15-25          | 0.00%
2-3         | 134 ms            | 25-40          | 0.00%
3-4         | 287 ms            | 40-60          | 0.31%
4-5         | 456 ms            | 60-80          | 0.89%
5-6         | 623 ms            | 70-80          | 1.45%
6-7         | 534 ms            | 60-70          | 1.12%
7-8         | 312 ms            | 40-50          | 0.45%
8-9         | 178 ms            | 20-30          | 0.00%
```

---

## 4. Анализ результатов

### 4.1 Устойчивость под нагрузкой

**Положительные наблюдения:**
- При нагрузке до 30 concurrent users система демонстрирует стабильную работу с временем отклика менее 150 мс.
- Общий процент ошибок 0.52% находится в допустимых пределах (норма < 1%).
- Операции чтения масштабируются линейно до определённого порога.
- Connection pooling работает корректно, нет ошибок получения соединения с БД.

**Проблемные области:**
- При превышении 50 concurrent users наблюдается резкий рост времени отклика.
- Максимальное время отклика 3421 мс указывает на периодические «заторы».
- POST-запросы при высокой нагрузке демонстрируют нестабильность (max 2134 мс).

### 4.2 Выявленные узкие места

**1. Эндпоинт GET /users (список):**
- При нагрузке 90-й перцентиль вырастает с 245 мс до 623 мс.
- Вероятная причина: отсутствие индекса на полях сортировки или неоптимальный запрос пагинации.
- Рекомендация: проверить план выполнения запроса, добавить индексы, рассмотреть использование cursor-based pagination.

**2. Операции записи (POST /users):**
- Высокая latency (99-й перцентиль: 876 мс) при относительно небольшом throughput.
- Вероятная причина: длительные транзакции, блокировки на уровне БД.
- Рекомендация: оптимизировать транзакционную логику, рассмотреть асинхронную валидацию.

**3. Деградация при 50+ пользователях:**
- Резкий рост ошибок timeout.
- Вероятная причина: исчерпание пула потоков Tomcat (default: 200), нехватка соединений к БД.
- Рекомендация: увеличить размер thread pool, настроить HikariCP connection pool.

### 4.3 Валидация ответов

Все ассерты на структуру JSON-ответов прошли успешно:
- Поле `content` присутствует в ответах GET /users — OK
- Поля `id`, `email` присутствуют в ответах GET /users/{id} — OK
- HTTP 201 возвращается для POST /users — OK (за исключением 0.51% ошибок)
- HTTP 200 возвращается для PUT /users — OK

Ошибки GET /users/{id} (0.14%) — это корректные 404 Not Found для несуществующих ID из CSV-файла.

---

## 5. Рекомендации по оптимизации

### Краткосрочные (quick wins):

1. **Добавить индексы в БД** на поля, используемые в WHERE и ORDER BY для эндпоинта списка пользователей.

2. **Включить кэширование** для GET-запросов (Spring Cache + Redis/Caffeine) с TTL 30-60 секунд для списка пользователей.

3. **Оптимизировать пул соединений HikariCP:**
   ```yaml
   spring:
     datasource:
       hikari:
         maximum-pool-size: 20
         minimum-idle: 5
         connection-timeout: 30000
   ```

### Среднесрочные:

4. **Перейти на cursor-based pagination** вместо offset-based для больших наборов данных.

5. **Внедрить rate limiting** для защиты от перегрузки (например, Bucket4j или Resilience4j RateLimiter).

6. **Добавить Circuit Breaker** для graceful degradation при перегрузке БД.

### Долгосрочные:

7. **Рассмотреть горизонтальное масштабирование** с load balancer при требованиях >100 concurrent users.

8. **Внедрить асинхронную обработку** для операций записи с использованием очередей сообщений.

---

## 6. Заключение

Проведённое нагрузочное тестирование показало, что REST API сервиса управления пользователями демонстрирует **удовлетворительную производительность при нормальной нагрузке** (до 30 одновременных пользователей). Среднее время отклика 178 мс и процент ошибок 0.52% соответствуют типичным требованиям для внутренних корпоративных систем.

Однако **при стресс-нагрузке (50+ пользователей) наблюдается деградация производительности**: время отклика увеличивается в 2-3 раза, появляются timeout-ошибки. Это указывает на необходимость оптимизации перед выходом в production с высокой нагрузкой.

**Ключевые метрики:**
- Пиковый throughput: 71.4 запросов/сек
- Среднее время отклика: 178 мс
- 95-й перцентиль: 534 мс
- Процент ошибок: 0.52%

**Оценка готовности к production:** система готова к эксплуатации с ограниченной пользовательской базой. Для масштабирования требуются оптимизации, описанные в разделе 5.

