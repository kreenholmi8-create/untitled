# Отчёт по лабораторной работе  
**Тема:** Сравнение REST + polling и WebSocket в клиент‑серверном взаимодействии  
**Проект:** `vacancy-parser` (Spring Boot 3.5.7, Java 21, H2, Thymeleaf, WebSocket)  

---

## 1) Цель и постановка задачи

**Цель:** сравнить два способа доставки результата длительной операции (парсинга) от сервера к фронтенду:

1) **REST + polling** — клиент запускает задачу и далее каждые 500 мс опрашивает сервер по `/status`.  
2) **WebSocket** — клиент запускает задачу, а сервер сам “пушит” обновления/результат в WebSocket‑канал по мере готовности.

**Требуемые замеры:**
- количество HTTP‑запросов за одну операцию (polling);
- общий объём переданных данных;
- время от запуска до получения результата;
- поведение при медленной обработке (имитация задержки 5 секунд).

---

## 2) Используемые инструменты и окружение

- **Backend:** Java 21, Spring Boot (Web MVC, WebSocket), H2, JPA.
- **Frontend:** HTML + JavaScript (одна страница сравнения).
- **Измерения:** Browser DevTools → вкладка Network (и встроенные счётчики в JS на странице `/comparison`).
- (Опционально по заданию) JMeter — пригоден для нагрузочных тестов, но приведённые ниже цифры получены из UI/DevTools.

---

## 3) Описание реализации обоих механизмов

### 3.1. Общая модель задачи парсинга (единая для обоих режимов)

**Ключевая сущность:** `ParsingStatus`  
Содержит:
- `taskId`
- `status`: `PENDING / IN_PROGRESS / COMPLETED / ERROR`
- `totalUrls`, `processedUrls`, `savedVacancies`
- `startedAt`, `completedAt`
- `results` (список `VacancyDto`)
- `errorMessage`

**Сервис хранения состояния:** `ParsingTaskService`
- `createTask(totalUrls)` — создаёт задачу и кладёт `ParsingStatus` в `ConcurrentHashMap`.
- `updateProgress(taskId, processed, vacancy)` — обновляет прогресс и добавляет результат.
- `completeTask(taskId, results)` / `failTask(...)` — финализирует задачу.

**Выполнение парсинга:** `ParseService.parseUrlsWithTracking(urls, delaySeconds)`
- Создаёт `taskId`.
- Отправляет работу в `ExecutorService` (пул потоков).
- (Для эксперимента) добавляет `Thread.sleep(delaySeconds * 1000)`.
- Для каждого URL: `fetchHtml(url)` → `parse(html)` → `save(vacancy)` → `updateProgress`.
- По завершении: `completeTask`.

Таким образом, **логика самой обработки одинакова**, различается только **способ доставки статуса/результата на фронт**.

---

### 3.2. REST + polling

**Backend endpoints:**
- `POST /api/parse/start?delaySeconds=N`  
  Тело: `{"urls":[...]}`
  Ответ: `{"taskId":"..."}`
- `GET /api/parse/status/{taskId}`  
  Ответ: `ParsingStatus` (включая `results`, что важно для трафика).

**Frontend‑логика (страница `/comparison`):**
1) Отправляет `POST /api/parse/start`.
2) Запускает `setInterval` с периодом `pollingInterval` (по заданию 500 мс).
3) На каждом тике делает `GET /api/parse/status/{taskId}` пока статус не станет `COMPLETED/ERROR`.
4) Ведёт счётчики:
   - `requests` (число HTTP запросов),
   - `dataIn` (сумма размеров JSON‑ответов),
   - `dataOut` (размер тела стартового запроса),
   - время от `startTime` до `endTime`.

**Особенность текущей реализации:** `/status` возвращает `results` (нарастающий список). Это резко влияет на входящий трафик: чем больше обработано URL, тем больше JSON каждого следующего ответа.

---

### 3.3. WebSocket

**Backend:**
- WebSocket endpoint: `/ws/parsing` (Spring `TextWebSocketHandler`)
- `POST /api/parse/ws?delaySeconds=N`  
  Возвращает `taskId` и подсказку `wsEndpoint`.

**Передача данных:**
- `ParsingTaskService.updateProgress(...)` вызывает `webSocketHandler.broadcastMessage(status)`.
- То есть при каждом обработанном URL сервер отправляет сообщение всем подключенным с актуальным `ParsingStatus`.

**Frontend:**
1) Открывает WebSocket `ws://host/ws/parsing`.
2) После `onopen` отправляет `POST /api/parse/ws`.
3) На каждое `onmessage`:
   - увеличивает `messages`,
   - добавляет `dataIn += event.data.length`,
   - парсит JSON и обновляет прогресс,
   - игнорирует сообщения чужих `taskId`.

**Важная особенность текущей реализации:**  
Отправка идёт через `broadcastMessage` всем активным сессиям (а не “ответ только инициатору”), а payload — полный `ParsingStatus`, включая `results` (нарастающий список). Это приводит к **взрывному росту трафика**, потому что:
- сообщений много (по факту 1 сообщение на каждый URL + финальное),
- каждое сообщение становится всё больше (список результатов растёт).

---

## 4) Результаты измерений и анализ

Ниже — ваши зафиксированные цифры.

### 4.1. Эксперимент: 100 URL, `delaySeconds=0`, polling=500 мс

| Метрика | REST + polling | WebSocket |
|---|---:|---:|
| HTTP‑запросов | 5 | 2 (handshake + start) |
| WS‑сообщений | — | 101 |
| Входящий трафик | 172.41 KB | 3268.67 KB |
| Исходящий трафик | 5.29 KB | 0 B (в UI счётчике; стартовый POST всё равно есть) |
| Итоговый трафик | 177.70 KB | 3268.67 KB |
| Время до результата | 2.04 сек | 2.08 сек |

**Интерпретация:**
- **По HTTP‑запросам** WebSocket ожидаемо выигрывает: вместо регулярных опросов — одно подключение и один стартовый POST.
- **По времени** в этом прогоне разницы почти нет: и там, и там результат получен примерно за 2 секунды.
- **По трафику WebSocket сильно проиграл** (примерно в 18–19 раз по суммарному входящему). Причина не в технологии как таковой, а в том, **как сформирован payload и частота сообщений**:
  - вы отправляете **101 сообщение**;
  - каждое сообщение несёт `ParsingStatus` с растущим `results`;
  - итого — многократная пересылка уже переданных данных.

Polling в вашем случае сделал лишь 4 запроса статуса, поэтому переслал “растущий результат” всего несколько раз.

---

### 4.2. Эксперимент: 1000 URL

| Метрика | REST + polling | WebSocket |
|---|---:|---:|
| HTTP‑запросов | 16 | 2 |
| Входящий трафик | 5832.69 KB | 315896.70 KB |
| Исходящий трафик | 53.05 KB | 0 B (по UI счётчику) |
| Итоговый трафик | 5885.74 KB | 315896.70 KB |
| Время до результата | 7.56 сек | 47.76 сек |

**Интерпретация:**
- **WebSocket снова выигрывает по числу HTTP‑запросов** (2 против 16).
- **Но по трафику проигрыш становится огромным** (десятки раз). Это напрямую следует из модели “1 URL → 1 сообщение” + “в сообщении весь список результатов”.
- **Неожиданно WebSocket проигрывает по времени** (47.76 сек против 7.56 сек). Наиболее вероятные причины в рамках текущей реализации:
  1) создаётся очень большой объём сериализации `ObjectMapper` (каждое сообщение становится всё тяжелее), CPU уходит в JSON;
  2) сеть/браузер перегружается обработкой тысяч крупных сообщений;
  3) сервер тратит время на рассылку в WebSocket‑сессии в рамках критичного пути прогресса (у вас отправка происходит при каждом `updateProgress`).

---

## 5) Поведение при медленной обработке (задержка 5 секунд)

В проекте задержка моделируется параметром `delaySeconds` в `ParseService.parseUrlsWithTracking` (в начале фоновой задачи стоит `Thread.sleep`).

Ожидаемое поведение:

- **REST + polling:**
  - клиент продолжает делать `GET /status` каждые 500 мс;
  - при 5 сек задержке до начала обработки получится порядка \(\frac{5}{0.5}=10\) “пустых” запросов статуса (плюс стартовый POST);
  - нагрузка на сервер растёт линейно от числа клиентов и обратно пропорциональна интервалу polling.

- **WebSocket:**
  - после handshake + start клиент просто “ждёт” и почти не создаёт дополнительной нагрузки запросами;
  - но как только обработка начнётся, при текущей стратегии “каждый шаг → сообщение” нагрузка на канал и сериализацию всё равно будет высокой.

---

## 6) Выводы: преимущества/недостатки подходов (по результатам проекта)

### REST + polling
**Плюсы:**
- простая реализация и отладка (обычные HTTP эндпойнты);
- предсказуемая нагрузка при редком polling;
- хорошо работает, если нужен только “финальный результат” или редкие обновления.

**Минусы:**
- лишние запросы при долгой обработке (особенно при 500 мс);
- задержка доставки результата зависит от интервала polling (в худшем случае почти один интервал);
- при большом количестве клиентов polling может стать заметной нагрузкой на сервер.

### WebSocket
**Плюсы:**
- push‑модель: результат приходит сразу по готовности, без опроса;
- меньше HTTP‑запросов, удобен для real‑time сценариев;
- естественно поддерживает поток обновлений.

**Минусы (проявились в ваших измерениях):**
- при отправке частых сообщений с “тяжёлым” payload (полный `results`) резко растёт трафик и CPU на сериализацию;
- при большом числе сообщений может ухудшаться время выполнения задачи (в вашем случае на 1000 URL время стало значительно больше);
- требуется аккуратная архитектура: адресная доставка (не broadcast), ограничение частоты, компактные сообщения.

---

## 7) Рекомендации по выбору подхода в разных сценариях

**Выбирать REST + polling**, если:
- нужен только итоговый статус/результат, а прогресс вторичен;
- клиентов немного, или polling можно сделать редким (например, 1–2 секунды);
- важнее простота и совместимость.

**Выбирать WebSocket**, если:
- важны “живые” обновления прогресса/событий в реальном времени;
- клиентов много и polling создаёт чрезмерные запросы;
- вы готовы оптимизировать модель сообщений.

**Практическая рекомендация именно для вашего проекта (чтобы WebSocket стал “быстрее и легче”, как ожидается):**
- не отправлять полный `ParsingStatus.results` на каждый прогресс‑тик; вместо этого:
  - слать компактный прогресс: `{taskId,status,processedUrls,totalUrls}`  
  - финальный результат отдавать один раз (последним сообщением) или отдельным REST‑эндпойнтом `GET /result/{taskId}`.
- отправлять сообщения адресно (в сессию инициатора), а не через `broadcastMessage`.
- ограничить частоту отправки (например, раз в 200–500 мс или “каждые N URL”), чтобы не слать 1000 сообщений подряд.

---

## 8) Приложение: что именно проверять в проекте

- Страница сравнения: `GET /comparison`
- **Polling:**
  - `POST /api/parse/start?delaySeconds=N`
  - `GET /api/parse/status/{taskId}`
- **WebSocket:**
  - подключение к `ws://localhost:8080/ws/parsing`
  - `POST /api/parse/ws?delaySeconds=N`
